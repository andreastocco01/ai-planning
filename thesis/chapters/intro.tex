\chapter{Introduction}
\label{ch:intro}
\textit{Automated Planning} (or AI Planning) is a core subfield of Artificial Intelligence.
It enables intelligent agents to reason about actions and outcomes to
achieve long-term objectives. It plays a vital role in applications such as robotics,
autonomous systems, logistics, and game AI, where efficient generation of high-quality plans is essential.
These real-world scenarios demand algorithms that can generate
high-quality plans efficiently under various constraints.\\
A planning problem, in general terms, can be defined as the task of finding a sequence
of actions that leads from a given initial state to a desired goal state.
While several formal models exist for defining planning problems, this thesis
adopts the \textit{$SAS^+$ formalism} defined in Definition \ref{def:sas+}

\begin{definition}[$\text{SAS}^+$ Planning Task]
	\label{def:sas+}
	A $\text{SAS}^+$ planning task is a 4-tuple $\Pi = \langle V, s_0, s_*, A \rangle$ with
	the following components:
	\begin{itemize}
		\item \(V\): finite set of state variables \(v\),
		      each with finite domain \textit{dom(v)}
		\item \(s_0\): variable assignment defining the initial state
		\item \(s_*\): partial variable assignment defining the goal
		\item \(A\): finite set of actions (or operators),
		      where each action $a \in A$ has the following components:
		      \begin{itemize}
			      \item Preconditions \textit{pre(a)}: partial variable assignment
			      \item Effects \textit{eff(a)}: partial variable assignment
			      \item Cost \textit{cost(a)}: non-negative real number
		      \end{itemize}
	\end{itemize}
\end{definition}

For an action $a \in A$ to be applicable, all of its preconditions
\textit{pre(a)} must be satisfied in the current state. Once applied, its effects
\textit{eff(a)} are used to update the current state accordingly.
In this context, a \textit{fact} is defined as the assignment of a value to a state variable,
i.e., an expression of the form $v = d$ with $v \in V$ and $d \in dom(v)$.
Thus, a state can be regarded as the set of facts that are satisfied simultaneously.
The solutions to planning problems are called \textit{plans}, and they are formally defined in Definition \ref{def:plan}

\begin{definition}[Plan]
	\label{def:plan}
	A plan for a planning problem is a sequence of actions occurring as labels on a path
	from the initial state to a goal state.
	The cost of a plan $\langle a_1, a_2, \dots, a_n \rangle$ is $\sum_{i = 1}^n cost(a_i)$.
	A plan is optimal if it has minimal cost.
\end{definition}

The class of problems considered in this thesis is a relaxation of the general $\text{SAS}^+$ model,
referred to as \textit{delete-free} planning.
In the standard formalism, applying an action may overwrite existing facts:
for instance, if a variable $v$ currently satisfies $v = d$, an effect setting $v = d'$
implicitly deletes the previous assignment.
In contrast, in the delete-free setting, actions never remove facts.
Once a fact becomes true, it remains true for the rest of the plan, even if the same variable
is later assigned a different value.
As a consequence, states are monotonic and may contain multiple values for the same variable,
distinguishing them from those of the original planning problem.
This structural property simplifies reasoning about reachability and reduces the complexity of
exploring the search space, while still retaining much of the problem's inherent difficulty.\\
Optimal planners, such as \textit{Fast Downward}, are guaranteed to find the best possible solution to a planning task, but they can be
computationally expensive. This thesis instead focuses on \textit{heuristic} algorithms, which aim to find high-quality solutions more efficiently,
even though they do not guarantee optimality.
Designing efficient heuristics for such domains is a key area of study, especially when exact solutions become impractical due to problem complexity.\\
After outlining the experimental methodology, the thesis presents several well-known heuristic algorithms for delete-free planning,
together with the implementation of a novel approach.
All algorithms are evaluated in terms of solution quality across a range of benchmark instances. In addition, the study explores the impact of
randomization on performance and investigates refinement strategies aimed at improving initial solutions.
