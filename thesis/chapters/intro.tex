\chapter{Introduction}
\label{ch:intro}
\textit{Automated Planning} (or AI Planning) is a core subfield of Artificial Intelligence.
It enables intelligent agents to reason about actions and outcomes to
achieve long-term objectives. It is crucial in applications ranging from robotics and autonomous
systems to logistics and game AI. These real-world scenarios demand algorithms that can generate
high-quality plans efficiently under various constraints.\\
A planning problem, in general terms, can be defined as the task of finding a sequence
of actions that leads from a given initial state to a desired goal state.
While several formal models exist for defining planning problems, this thesis
adopts the \textit{$SAS^+$ formalism} defined in Definition \ref{def:sas+}

\begin{definition}[$\text{SAS}^+$ Planning Task]
	\label{def:sas+}
	A $\text{SAS}^+$ planning task is a 5-tuple $\Pi = \langle V, s_0, s_*, A \rangle$ with
	the following components:
	\begin{itemize}
		\item \(V\): finite set of state variables \(v\),
		      each with finite domain \textit{dom(v)}
		\item \(s_0\): variable assignment defining the initial state
		\item \(s_*\): partial variable assignment defining the goal
		\item \(A\): finite set of actions (or operators),
		      where each action $a \in A$ has the following components:
		      \begin{itemize}
			      \item Preconditions \textit{pre(a)}: partial variable assignment
			      \item Effects \textit{eff(a)}: partial variable assignment
			      \item Cost \textit{cost(a)}: non-negative real number
		      \end{itemize}
	\end{itemize}
\end{definition}

For an action $a \in A$ to be applicable, all of its preconditions
\textit{pre(a)} must be satisfied in the current state. Once applied, its effects
\textit{eff(a)} are used to update the current state accordingly.
In the simplified class of problems considered in this thesis|referred to as \textit{Delete-Free}|actions do not have any negative effects.
This assumption makes the state space monotonic: once a fact becomes true, it remains true throughout the plan.
As a result, reasoning about goal reachability becomes simpler, and the complexity introduced by the potential removal of facts is avoided.
This structural property enables more efficient exploration of the search space and facilitates the analysis of action dependencies.
Despite this relaxation, delete-free planning preserves many of the essential characteristics of the original problem.\\
The solutions to planning problems are called \textit{plans}, and they are formally defined in Definition \ref{def:plan}

\begin{definition}[Plan]
	\label{def:plan}
	A plan for a planning problem is a sequence of actions occurring as labels on a path
	from the initial state to a goal state.
	The cost of a plan $\langle a_1, a_2, \dots, a_n \rangle$ is $\sum_{i = 1}^n cost(a_i)$.
	A plan is optimal if it has minimal cost.
\end{definition}

Optimal planners, such as \textit{Fast Downward}, are guaranteed to find the best possible solution to a planning task, but they can be
computationally expensive. This thesis instead focuses on \textit{heuristic} algorithms, which aim to find high-quality solutions more efficiently,
even though they do not guarantee optimality.
Designing efficient heuristics for such domains is a key area of study, especially when exact solutions become impractical due to problem complexity.\\
The thesis begins by presenting several well-known heuristic algorithms for delete-free planning, alongside the implementation of a novel approach.
All algorithms are evaluated in terms of solution quality across a range of benchmark instances. In addition, the study explores the impact of
randomization on performance and investigates refinement strategies aimed at improving initial solutions.
