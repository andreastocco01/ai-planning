\chapter{Methodology}
\label{ch:methodology}
This chapter outlines the methodological approach used to compare the selected algorithms.
Several algorithms and variations were implemented in this thesis. Some
were chosen solely as baselines for the experiments, such as Random and Greedy.
As their names suggest, the former selects a random action at each iteration, while the latter
always chooses the action with the minimum cost.
The $h^{\max}$ heuristic \cite{bonet2001planning} is one of the most important
heuristics in Delete Free AI Planning problems. A revised version of this heuristic, incorporating
a pruning logic, is proposed in this work.
Additionally, a novel heuristic was developed, which assigns to each action the cost of the shortest path to reach the goal
state and then selects the action that is closest to the goal.\\
The experiments were conducted on a testbed containing 3,104 domain-independent instances.
Each algorithm was run on every instance with 10 different random seeds, resulting in 31,040 runs
per algorithm. A time limit of 60 seconds was set for each run.
All experiments presented in this thesis were conducted on a computing cluster maintained by the Operations Research group at the
Department of Information Engineering (DEI), University of Padova.
The cluster consists of 15 identical blades, each equipped with an Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz, 16GB of RAM, and running Fedora 37.
The algorithms were compared in terms of solution cost, where a lower cost indicates a better solution.
To evaluate the effectiveness of the algorithms, a \textit{cumulative distribution plot} is used.
The concept of the primal gap, originally defined in the context of Mixed Integer Programming (MIP)
(see Definition \ref{def:primalgap}) \cite{berthold2013measuring}, is adapted here to quantify the quality of solutions across algorithms.

\begin{definition}[Primal Gap]
	\label{def:primalgap}
	Let \~x be a solution for a problem, and $\text{\~x}_{opt}$ be an optimal (or best known)
	solution for that problem. We define the primal gap $\gamma \in \left[0, 1\right]$ of \~x as follows:
	\begin{equation*}
		\gamma\left(\text{\~x}\right)\coloneqq\begin{cases}
			0,                                                                                                                            & \text{if $\lvert c^T\tilde{x}_{opt}\rvert$ = $\lvert c^T\tilde{x}\rvert$ = 0}, \\
			1,                                                                                                                            & \text{if $c^T\tilde{x}_{opt} \cdot c^T\tilde{x} < 0$},                         \\
			\frac{\lvert c^T\tilde{x}_{opt} - c^T\tilde{x} \rvert}{max \{\lvert c^T\tilde{x}_{opt} \rvert, \lvert c^T\tilde{x} \rvert\}}, & \text{else}.
		\end{cases}
	\end{equation*}
\end{definition}

An algorithm that finds the best solution for a given instance will exhibit a primal gap of zero.
For all other algorithms, the primal gap approaches zero as the solution quality approaches the best known,
and approaches one as it deviates further from it.
For each algorithm, a cumulative distribution plot is generated by plotting the percentage of instances
on which the algorithm has a primal gap below a given threshold. A more detailed explanation of this analysis will be provided in the following sections.
